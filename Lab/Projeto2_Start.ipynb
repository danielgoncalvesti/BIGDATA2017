{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseId\tSentenceId\tPhrase\tSentiment\n",
      "[u'1\\t1\\tA series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\\t1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "filename = os.path.join(\"Data\",\"Aula04\",\"MovieReviews.tsv\")\n",
    "rawRDD = sc.textFile(filename,2)\n",
    "header = rawRDD.take(1)[0]\n",
    "\n",
    "dataRDD = rawRDD.filter(lambda x: x!=header)\n",
    "\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "rawTrainData, rawValidationData, rawTestData = dataRDD.randomSplit(weights, seed)\n",
    "# Cache the data\n",
    "rawTrainData.cache()\n",
    "rawValidationData.cache()\n",
    "rawTestData.cache()\n",
    "\n",
    "'''\n",
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/\n",
    "\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive\n",
    "'''\n",
    "\n",
    "print header\n",
    "print dataRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for featureString in rawFeats.split():\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)\n",
    "\n",
    "def parseTextPoint(point, numBuckets):\n",
    "    id1, id2, text, sent = point.split('\\t')\n",
    "    sent = int(sent)\n",
    "    if sent < 2:\n",
    "        label = 0\n",
    "    elif sent > 2:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "    features = SparseVector(numBuckets,hashFunction(numBuckets, text))\n",
    "    \n",
    "    return LabeledPoint(label,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (5000,[96,122,143,479,664,1138,1224,1351,1425,1497,1635,1648,1793,2084,2405,2539,2920,3214,3672,3804,3849,3876,4057,4345,4380,4675,4870,4993],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "numBuckets = 5000\n",
    "parsedTrainData = rawTrainData.map(lambda x: parseTextPoint(x, numBuckets)).cache()\n",
    "parsedValData = rawValidationData.map(lambda x: parseTextPoint(x, numBuckets)).cache()\n",
    "parsedTestData = rawTestData.map(lambda x: parseTextPoint(x, numBuckets)).cache()\n",
    "\n",
    "binTrainData = parsedTrainData.filter(lambda x: x.label!=2).cache()\n",
    "binValData = parsedValData.filter(lambda x: x.label!=2).cache()\n",
    "binTestData = parsedTestData.filter(lambda x: x.label!=2).cache()\n",
    "\n",
    "print parsedTrainData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcAccuracy( predsAndVals ):\n",
    "    return predsAndVals.map(lambda x: x[0]==x[1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Validation Accuracy = 0.542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posClassCount = parsedTrainData.filter(lambda x: x.label==1).count()\n",
    "negClassCount = parsedTrainData.filter(lambda x: x.label==0).count()\n",
    "baseLine = 1 if posClassCount > negClassCount else 0\n",
    "\n",
    "labelsAndPreds = binValData.map(lambda x: (baseLine,x.label))\n",
    "accValBaseline = calcAccuracy(labelsAndPreds)\n",
    "print  'Baseline Validation Accuracy = {0:.3f}\\n'.format(accValBaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

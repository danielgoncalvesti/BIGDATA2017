{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "baseDir = os.path.join('Data')\n",
    "inputPath = os.path.join('Aula04', 'BikeSharing.csv')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "numPartitions = 2\n",
    "csvData = sc.textFile(fileName, numPartitions)\n",
    "header = csvData.take(1)[0]\n",
    "rawData = csvData.filter(lambda x: x!=header)\n",
    "\n",
    "'''\n",
    "https://www.kaggle.com/c/bike-sharing-demand\n",
    "datetime - hourly date + timestamp  \n",
    "season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "holiday - whether the day is considered a holiday\n",
    "workingday - whether the day is neither a weekend nor holiday\n",
    "weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "temp - temperature in Celsius\n",
    "atemp - \"feels like\" temperature in Celsius\n",
    "humidity - relative humidity\n",
    "windspeed - wind speed\n",
    "casual - number of non-registered user rentals initiated\n",
    "registered - number of registered user rentals initiated\n",
    "count - number of total rentals\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
      "\n",
      "[u'2011-01-01 00:00:00,1,0,0,1,9.84,14.395,81,0,3,13,16']\n"
     ]
    }
   ],
   "source": [
    "print header\n",
    "print\n",
    "print rawData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8761\n",
      "0.0133333333333\n",
      "0.0082\n",
      "0.0217391304348\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "0.797456140351\n",
      "0.41\n",
      "0.0869565217391\n",
      "0.0243902439024\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# alterar essa c√©lula invalida o projeto!!!\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    data = point.split(',')\n",
    "    Date = dt.strptime(data[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    DateList = [Date.year-2011, Date.month/12.0, Date.hour/24.0]\n",
    "    \n",
    "    season = [0]*4\n",
    "    season[int(data[1])-1] = 1\n",
    "    \n",
    "    dividends = [4., 41., 46., 100., 57.]\n",
    "    realValues =  map(lambda x: float(x[0])/x[1], zip(data[2:-3], dividends))\n",
    "    \n",
    "    features = DenseVector(DateList + season + realValues)\n",
    "    \n",
    "    label = int(data[-1])\n",
    "    \n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "\n",
    "rawTrainData, rawValData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "\n",
    "parsedTrainData = rawTrainData.map(parsePoint).cache()\n",
    "parsedValData = rawValData.map(parsePoint).cache()\n",
    "parsedTestData = rawTestData.map(parsePoint).cache()\n",
    "\n",
    "print parsedTrainData.count()\n",
    "\n",
    "print parsedTrainData.map(lambda x: x.features[-1]).min()\n",
    "print parsedTrainData.map(lambda x: x.features[-2]).min()\n",
    "print parsedTrainData.map(lambda x: x.features[-3]).min()\n",
    "print parsedTrainData.map(lambda x: x.features[-4]).min()\n",
    "print parsedTrainData.map(lambda x: x.features[-5]).min()\n",
    "print\n",
    "print parsedTrainData.map(lambda x: x.features[-1]).max()\n",
    "print parsedTrainData.map(lambda x: x.features[-2]).max()\n",
    "print parsedTrainData.map(lambda x: x.features[-3]).max()\n",
    "print parsedTrainData.map(lambda x: x.features[-4]).max()\n",
    "print parsedTrainData.map(lambda x: x.features[-5]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squaredError(label, prediction):\n",
    "    \"\"\"Calculates the the squared error for a single prediction.\n",
    "\n",
    "    Args:\n",
    "        label (float): The correct value for this observation.\n",
    "        prediction (float): The predicted value for this observation.\n",
    "\n",
    "    Returns:\n",
    "        float: The difference between the `label` and `prediction` squared.\n",
    "    \"\"\"\n",
    "    return np.square(label-prediction)\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
    "\n",
    "    Args:\n",
    "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    return np.sqrt(labelsAndPreds.map(lambda rec: squaredError(rec[0],rec[1])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.685766465\n"
     ]
    }
   ],
   "source": [
    "averageBike = parsedTrainData.map(lambda lp: lp.label).mean()\n",
    "print averageBike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train RMSE: 181.530\n",
      "Baseline Validation RMSE: 180.371\n"
     ]
    }
   ],
   "source": [
    "labelsAndPredsTrain = parsedTrainData.map(lambda rec: (rec.label, averageBike))\n",
    "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "labelsAndPredsVal = parsedValData.map(lambda rec: (rec.label, averageBike))\n",
    "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
    "\n",
    "print 'Baseline Train RMSE: {:.3f}'.format(rmseTrainBase)\n",
    "print 'Baseline Validation RMSE: {:.3f}'.format(rmseValBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Os desafios devem ser obtidos na base de text (parsedTestData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
